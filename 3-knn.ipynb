{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step of lab 1 you will code and understand basic steps of image classification, including cross-validation, using a KNN classifier.\n",
    "\n",
    "Answers to the questions embedded in this code should be added to the file \"submission.py\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Confirm we have the expected 50,000 training Images:\n50000\n50000\n\nConfirm we have the expected 10,000 test Images:\n10000\n10000\n\nConfirm the first image in our training set is a 32x32x3 matrix of values, representing a 32x32 image with 3 bands of color:\n(32, 32, 3)\nTrue\n\nConfirm our y observations make sense - i.e., an integer between 0 and 9 representing one of the 10 classes in CIFAR\n6\n9\n0\n"
     ]
    }
   ],
   "source": [
    "#First, let's load in the data we created in the previous step.\n",
    "import pickle\n",
    "\n",
    "with open(\"testTrainLab1.pickle\", \"rb\") as f:\n",
    "    labData = pickle.load(f)\n",
    "\n",
    "print(\"Confirm we have the expected 50,000 training Images:\")\n",
    "print(len(labData[\"X_train\"]))\n",
    "print(len(labData[\"y_train\"]))\n",
    "\n",
    "print(\"\\nConfirm we have the expected 10,000 test Images:\")\n",
    "print(len(labData[\"X_test\"]))\n",
    "print(len(labData[\"y_test\"]))\n",
    "\n",
    "print(\"\\nConfirm the first image in our training set is a 32x32x3 matrix of values, representing a 32x32 image with 3 bands of color:\")\n",
    "print(labData[\"X_train\"][0].shape)\n",
    "print(str(labData[\"X_train\"][0].shape) == \"(32, 32, 3)\")\n",
    "\n",
    "print(\"\\nConfirm our y observations make sense - i.e., an integer between 0 and 9 representing one of the 10 classes in CIFAR\")\n",
    "print(labData[\"y_train\"][0])\n",
    "print(max(labData[\"y_train\"]))\n",
    "print(min(labData[\"y_train\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[[ 59.  62.  63.]\n  [ 43.  46.  45.]\n  [ 50.  48.  43.]\n  ...\n  [158. 132. 108.]\n  [152. 125. 102.]\n  [148. 124. 103.]]\n\n [[ 16.  20.  20.]\n  [  0.   0.   0.]\n  [ 18.   8.   0.]\n  ...\n  [123.  88.  55.]\n  [119.  83.  50.]\n  [122.  87.  57.]]\n\n [[ 25.  24.  21.]\n  [ 16.   7.   0.]\n  [ 49.  27.   8.]\n  ...\n  [118.  84.  50.]\n  [120.  84.  50.]\n  [109.  73.  42.]]\n\n ...\n\n [[208. 170.  96.]\n  [201. 153.  34.]\n  [198. 161.  26.]\n  ...\n  [160. 133.  70.]\n  [ 56.  31.   7.]\n  [ 53.  34.  20.]]\n\n [[180. 139.  96.]\n  [173. 123.  42.]\n  [186. 144.  30.]\n  ...\n  [184. 148.  94.]\n  [ 97.  62.  34.]\n  [ 83.  53.  34.]]\n\n [[177. 144. 116.]\n  [168. 129.  94.]\n  [179. 142.  87.]\n  ...\n  [216. 184. 140.]\n  [151. 118.  84.]\n  [123.  92.  72.]]]\n[ 59.  62.  63. ... 123.  92.  72.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#Here, we're going to reshape our image data\n",
    "#Right now, it's in matrices - i.e., the below will print out a matrix, \n",
    "#where each line of the matrix is a list:\n",
    "print(labData[\"X_train\"][0])\n",
    "\n",
    "#While we could use that data, it's less effecient than doing array\n",
    "#manipulations, where every value is in a single list.  Using array manipulations\n",
    "#Greatly speeds up our code - while that isn't terribly important for this lab,\n",
    "#it will be critical in the future, so let's get used to it now.\n",
    "#This will reshape into rows - we'll also go ahead and unpack from our dict.\n",
    "X_train = np.reshape(labData[\"X_train\"], (labData[\"X_train\"].shape[0], -1))\n",
    "X_test = np.reshape(labData[\"X_test\"], (labData[\"X_test\"].shape[0], -1))\n",
    "\n",
    "#Reshaped Matrix - note the first value is still '59', then '62', just like in the matrix form - it's just a long list now:\"\n",
    "print(X_train[0])\n",
    "\n",
    "#Note our y values are just vectors, so nothing fancy we need to do.\n",
    "#We could use the dictionary, but for consistency I am transforming these into\n",
    "#variables.\n",
    "y_train = labData[\"y_train\"]\n",
    "y_test = labData[\"y_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "249 (99.6%)\n"
     ]
    }
   ],
   "source": [
    "#Here is our nearest neighbor classifier, \n",
    "#copied from the lecture notes.\n",
    "#We're going to train it with our CIFAR data, then\n",
    "#apply it (this will take a good while to run - as noted\n",
    "#in lecture, this is a VERY ineffecient algorithm.)\n",
    "#In the next snippet, we'll look at how well it does.\n",
    "\n",
    "#Note this is a function that lets us build a loop\n",
    "#That shows our progress in Jupyter, clearing the output\n",
    "#and replacing it with the current iteration (out of 10,000)\n",
    "from IPython.display import clear_output\n",
    "\n",
    "class NearestNeighbor:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def train(self, X, y):\n",
    "        self.Xtr = X\n",
    "        self.ytr = y\n",
    "\n",
    "    def predict(self, X):        \n",
    "        Ypred = np.zeros(len(X), dtype=np.dtype(self.ytr.dtype))\n",
    "\n",
    "        for i in range(0, len(X)):\n",
    "            l1Distances = np.sum(np.abs(self.Xtr - X[i]), axis=1)\n",
    "            minimumDistance = np.argmin(l1Distances)\n",
    "            Ypred[i] = self.ytr[minimumDistance]\n",
    "            \n",
    "            #Added so we can see the code progress:\n",
    "            clear_output(wait=True)\n",
    "            print(str(i) + \" (\" + str((i/len(X))*100) + \"%)\")\n",
    "        \n",
    "        return Ypred\n",
    "\n",
    "nnClass = NearestNeighbor()\n",
    "nnClass.train(X_train, y_train)\n",
    "\n",
    "yTestPredict = nnClass.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Our nearest neighbor classifier got it right 88 times out of our 250 test images.\nThat gives us an accuracy of 35.199999999999996%!\n"
     ]
    }
   ],
   "source": [
    "correctPred = np.sum(yTestPredict == y_test)\n",
    "print(\"Our nearest neighbor classifier got it right \" + str(correctPred) + \" times out of our \"+str(len(y_test))+\" test images.\")\n",
    "print(\"That gives us an accuracy of \" + str((correctPred / len(y_test)) * 100) + \"%!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As you saw, nn is VERY slow.  Pretty obvious\n",
    "#why it isn't used in practical cases!\n",
    "#So, lets subset\n",
    "#our testing data a bit to make things quicker.\n",
    "#We'll just take the first few observations.\n",
    "#If you re-run the above training and testing snippet\n",
    "#It will nnow be much, much, much faster!\n",
    "\n",
    "y_test = y_test[:250]\n",
    "X_test = X_test[:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "249 (99.6%)\nOur nearest neighbor classifier got it right 90 times out of our 250 test images.\nThat gives us an accuracy of 36.0%!\n"
     ]
    }
   ],
   "source": [
    "#Alright!  Now we want to extend our class to enable\n",
    "#A choice of K - i.e., we want to choose\n",
    "#A number of cases that are similar to what we want to predict\n",
    "#Not just the single most similar case.\n",
    "\n",
    "#You'll note in the below code that our training\n",
    "#doesn't change at all - we're only modifying our prediction.\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "class KNearestNeighbor:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def train(self, X, y):\n",
    "        self.Xtr = X\n",
    "        self.ytr = y\n",
    "\n",
    "    #First, in our prediction function we now need to take in a new\n",
    "    #variable - k.\n",
    "    def predict(self, X, k):        \n",
    "        Ypred = np.zeros(len(X), dtype=np.dtype(self.ytr.dtype))\n",
    "\n",
    "        for i in range(0, len(X)):\n",
    "            l1Distances = np.sum(np.abs(self.Xtr - X[i]), axis=1)\n",
    "\n",
    "            #In our older code, we just took the single\n",
    "            #minimum distance, and then looked up the class\n",
    "            #it belonged to.  Now we're going to do a vote\n",
    "            #of the k closest.\n",
    "            \n",
    "            #First, we're going to look up the indices in our\n",
    "            #array that represent the smallest values of distance.\n",
    "            #It's sorted ascending, so the first index is the index\n",
    "            #in the list l1Distances that is the smallest.\n",
    "            #so, for example, l1Distances[minimumIndices[0]] would give\n",
    "            #the smallest distance between the test image and all other images.\n",
    "            minimumIndices = np.argsort(l1Distances)\n",
    "            \n",
    "            #Now, we want to grab the indices of the closest \"k\" matches:\n",
    "            kClosest = minimumIndices[:k]\n",
    "            \n",
    "            #Now that we have the indices, we want to find the mode (i.e.,\n",
    "            #the most common class of neighbors):\n",
    "            #Note - ties are broken based on the order of the array, so for example\n",
    "            #if a \"1\" is encountered before a \"0\", and 0 and 1 are tied, 1 \"wins\".\n",
    "            predClass, counts = np.unique(self.ytr[kClosest], return_counts=True)\n",
    "            Ypred[i] = predClass[counts.argmax()]\n",
    "            \n",
    "            #Added so we can see the code progress:\n",
    "            clear_output(wait=True)\n",
    "            print(str(i) + \" (\" + str((i/len(X))*100) + \"%)\")\n",
    "        \n",
    "        return Ypred\n",
    "\n",
    "knnClass = KNearestNeighbor()\n",
    "knnClass.train(X_train, y_train)\n",
    "\n",
    "yTestPredictKNN = knnClass.predict(X_test, k=5)\n",
    "\n",
    "correctPredKNN = np.sum(yTestPredictKNN == y_test)\n",
    "print(\"Our nearest neighbor classifier got it right \" + str(correctPredKNN) + \" times out of our \"+str(len(y_test))+\" test images.\")\n",
    "print(\"That gives us an accuracy of \" + str((correctPredKNN / len(y_test)) * 100) + \"%!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}